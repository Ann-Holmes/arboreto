{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arboreto Tutorial\n",
    "\n",
    "This notebook is a tutorial on how to use Arboreto to infer gene regulatory networks (GRN) from gene expression data.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Arboreto architecture](#1-Arboreto-architecture)\n",
    "2. [Arboreto GRN inference algorithms](#2-Arboreto-GRN-inference-algorithms)\n",
    "3. [Setup in Jupyter Notebook or JupyterLab](#3-Setup-in-Jupyter-Notebook-or-JupyterLab)\n",
    "4. [Arboreto API](#4-Arboreto-API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1 Arboreto architecture\n",
    "\n",
    "Arboreto is a computational framework that hosts GRN inference algorithms that follow the __*\"Multiple Ensemble\"*__ inference strategy, of which [GENIE3](http://www.montefiore.ulg.ac.be/~huynh-thu/GENIE3.html) is probably the most well-known example. \n",
    "\n",
    "> *This method approaches the network inference problem by decomposing\n",
    "it into a separate regression problem for each possible target\n",
    "gene. Next, using a tree-based ensemble method, an importance\n",
    "measure for each predictor is calculated and a high feature\n",
    "importance is used as an indication that a link is present between\n",
    "the predictor and the target gene in the GRN.*\n",
    "\n",
    "> Ref: [NIMEFI: Gene Regulatory Network Inference using Multiple Ensemble Feature Importance Algorithms](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0092709). Ruyssinck et al. (2014) PLoS ONE\n",
    "\n",
    "It is often mentioned that the inference strategy of computing a regression per target is highly parallelizable, and can therefore by run in parallel on multiple compute nodes in a cluster. Arboreto answers this call by representing this computation in a [Dask](https://dask.pydata.org/en/latest/install.html) computation graph, enabling the computational workload to scale out over multiple CPU cores (scaling *up*) as well as over multiple compute nodes (scaling *out*).\n",
    "\n",
    "Arboreto uses only a small subset of the Dask API: Dask [delayed](https://dask.pydata.org/en/latest/delayed.html) functions and Dask [DataFrames](https://dask.pydata.org/en/latest/dataframe.html). Arboreto uses these building blocks to create a [custom graph](https://dask.pydata.org/en/latest/custom-graphs.html). A [Dask](https://dask.pydata.org/en/latest/install.html) graph can be regarded as a *recipe* that is executed by a Dask [scheduler](https://dask.pydata.org/en/latest/scheduler-overview.html), the Dask component that orchestrates the computational tasks.\n",
    "\n",
    "As a user of Arboreto, it is not necessary to master these concepts, they remain hidden behind the [Arboreto API](#4-Arboreto-API)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2 Arboreto GRN inference algorithms\n",
    "\n",
    "## 2.1 GRNBoost2\n",
    "Arboreto implements GRNBoost2, an improved version of the [GRNBoost](https://github.com/aertslab/GRNBoost/) algorithm that was originally built on [Xgboost](https://xgboost.readthedocs.io/en/latest/), using [Apache Spark](http://spark.apache.org/) as the computation engine. \n",
    "\n",
    "GRNBoost2 uses the scikit-learn [GradientBoostingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html). GRNBoost2 uses [early-stopping](https://en.wikipedia.org/wiki/Early_stopping) regularization and a modified feature importances normalization that compensates for the issue of comparing regression ensembles of different sizes when composing a GRN from the feature importances of different regressions.\n",
    "\n",
    "## 2.2 GENIE3\n",
    "Arboreto implements the GENIE3 specification by providing the GENIE3 recommended parameters for the scikit-learn [RandomForestRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3 Setup in Jupyter Notebook or JupyterLab\n",
    "\n",
    "It is recommended to use a recent (TODO: versions) [Anaconda](https://docs.anaconda.com/) or [Miniconda](https://conda.io/miniconda.html) distribution.\n",
    "\n",
    "## 3.1 Arboreto dependencies\n",
    "* [numpy](https://anaconda.org/anaconda/numpy)\n",
    "* [scikit-learn](http://scikit-learn.org/stable/install.html)\n",
    "* [pandas](https://pandas.pydata.org/pandas-docs/stable/install.html)\n",
    "* [dask](https://dask.pydata.org/en/latest/install.html) and optionally [dask-distributed](http://distributed.readthedocs.io/en/latest/install.html)\n",
    "\n",
    "## 3.2 Setup from source\n",
    "\n",
    "Arboreto is very lightweight python package that can be used from a [Jupyter Notebook](http://jupyter.org/) or [JupyterLab](https://github.com/jupyterlab/jupyterlab) environment by importing the `core.py` file.\n",
    "\n",
    "```\n",
    "$ git clone https://github.com/tmoerman/arboreto\n",
    "$ cd arboreto/notebooks\n",
    "$ jupyter lab\n",
    "```\n",
    "\n",
    "First, add the Arboreto source file to the `sys.path`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')  # path to the arboreto root folder\n",
    "\n",
    "from arboreto.core import *\n",
    "from arboreto.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Arboreto functions are now available in the notebook.\n",
    "\n",
    "## 3.3 Setup with Pip\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4 Arboreto API\n",
    "\n",
    "Arboreto aims at providing a minimal API, using only common python idioms and data structures.\n",
    "\n",
    "## 4.1 Creating a Dask computation graph\n",
    "\n",
    "The heart of Arboreto is the `create_graph` function that creates the Dask computation graph in function of the input data, the regressor parameters and a few optional parameters that are unnecessary in typical use.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "graph = create_graph(zeisel_ex_matrix,\n",
    "                     zeisel_gene_names,\n",
    "                     zeisel_tf_names,\n",
    "                     \"GBM\",\n",
    "                     SGBM_KWARGS)\n",
    "```\n",
    "\n",
    "You can use the question mark `?` in Jupyter to inspect a function's documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregressor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregressor_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_genes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop_window_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m666\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Main API function. Create a Dask computation graph.\n",
       "\n",
       ":param expression_matrix: numpy matrix. Rows are observations and columns are genes.\n",
       ":param gene_names: list of gene names. Each entry corresponds to the expression_matrix column with same index.\n",
       ":param tf_names: list of transcription factor names. Should have a non-empty intersection with gene_names.\n",
       ":param regressor_type: regressor type. Case insensitive.\n",
       ":param regressor_kwargs: dict of key-value pairs that configures the regressor.\n",
       ":param target_genes: either int, 'all' or a collection that is a subset of gene_names.\n",
       ":param limit: int or None. Default 100k. The number of top regulatory links to return.\n",
       ":param include_meta: Also return the meta DataFrame. Default False.\n",
       ":param early_stop_window_length: window length of the early stopping monitor.\n",
       ":param seed: (optional) random seed for the regressors.\n",
       ":return: if include_meta is False, returns a Dask graph that computes the links DataFrame.\n",
       "         If include_meta is True, returns a tuple: the links DataFrame and the meta DataFrame.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/work/batiskav/projects/arboreto/arboreto/core.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Input parameters\n",
    "\n",
    "Arboreto expects the input data in a specific shape\n",
    "\n",
    "#### `expression_matrix`\n",
    "\n",
    "* A [numpy matrix](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.matrix.html) where the __rows are observations__ and the __columns are genes__.\n",
    "\n",
    "> **CAUTION **\n",
    "\n",
    "> This is contrary to common practice in biology where the rows are the genes and the columns are the observations (e.g. cells). \n",
    "> We chose the orientation that is expected by the scikit-learn regressors to keep the library as minimal as possible. It is the responsibility of the user to provide the expression matrix in the correct orientation.\n",
    "\n",
    "#### `gene_names`\n",
    "\n",
    "* A list of gene names, in the same order as the columns of the `expression_matrix`. \n",
    "* Consider it the header of the numpy matrix.\n",
    "\n",
    "#### `tf_names`\n",
    "\n",
    "* A list of transcription factor (predictor) names. No particular ordering is required. \n",
    "* Arboreto expects that there is a non-empty intersection between `gene_names` and `tf_names`.\n",
    "\n",
    "#### `regressor_type`\n",
    "\n",
    "* One of `[\"RF\", \"GBM\", \"ET\"]`: specifies which scikit-learn regressor to use:\n",
    "\n",
    "\n",
    "| type  | regressor | algorithm |\n",
    "| ---   | ---       | ---         |\n",
    "| `RF`  | `RandomForestRegressor` | GENIE3 default with Random Forest |\n",
    "| `ET`  | `ExtraTreesRegressor`   | GENIE3 alternative with Extra-Trees |\n",
    "| `GBM` | `GradientBoostingRegressor` | GRNBoost2  |\n",
    "\n",
    "#### `regressor_kwargs`\n",
    "\n",
    "* A python dictionary of keyword-argument pairs (hence kwargs) to configure the scikit-learn regressor.\n",
    "\n",
    "### 4.2 Computing the GRN from a Dask graph\n",
    "\n",
    "As mentioned earlier, a Dask graph does not perform the computations, it is merely the computational *recipe* intepreted and executed by a Dask [scheduler](https://dask.pydata.org/en/latest/scheduler-choice.html).\n",
    "\n",
    "Arboreto is typically used with the Dask distributed scheduler, which can be used to run the computations with multiple processes on a single machine or using multiple machines connected to the scheduler.\n",
    "\n",
    "#### Computing on a single machine (easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
